https://www.javatpoint.com/dialogflow::dialogflow | dialogflow tutorial - javatpoint â‡§ scroll to top home dialogflow java javascript xml python robotics c embedded system sql html css android quiz projects interview q comment forum dialogflow tutorial dialogflow tutorial dialogflow tutorial dialogflow is a google service which operates on a google cloud platform. the dialogflow is an intuitive and user-friendly tool that includes google's machine learning expertise and some google products such as google cloud speech-to-text. dialogflow is an nlp (natural language processing) platform, which is used to develop an application related to the conversations and experience for the customers of the company in different languages on numerous platforms. dialogflow is mainly used to build actions for most of the google assistant devices. in our dialogflow tutorial, we are going to discuss the following topics- what is dialogflow features of the dialogflow use cases of dialogflow advantages of dialogflow why choose dialogflow? basics of dialogflow components of the dialogflow how to create your first dialogflow agent how to import the example file to your agent how to create a new intent how to create parameter in dialogflow how to create your own entities how to use your new entity contexts how to customize the default welcome intent how to create a custom intent how to customize the fallback intent create an intent with parameters knowledge base in dialogflow training in dialogflow intent matching with follow-up intent integration with an integration how to build resume chatbot for google assistant how to build an appointment scheduler with dialogflow how to build a chatbot for a faq with dialogflow what is dialogflow dialogflow is defined as a google service which operates on a google cloud platform. the dialogflow is an intuitive and user-friendly tool that includes some google products such as google cloud speech-to-text and google's machine learning expertise. it is mainly used to build actions for most of the google assistant devices. in other words, dialogflow is defined as an nlp (natural language processing) platform, which is used to develop an application related to the conversations and experience for the customers of the company in different languages on numerous platforms. by using google-powered, products developers can design text-based and voice-conversation interfaces in order to answer the queries of customers in various languages. for example - various companies use dialogflow to make messaging bots that reply to the queries of the customers on different platforms such as google assistant, slack, facebook messenger, alexa voice search (avs), etc. features of the dialogflow there are various features of the dialogflow: develop serverless apps easy deliver automated phone service designed for a voice-first world reply on automatic spelling correction improve experience with built-in analytics understand user sentiment deploy across platforms and languages bring your enterprise knowledge powered by google machine learning develop serverless apps easy there is a unified code editor offered by the google dialogflow through which we can easily develop natively serverless apps which are connected to our conversational interface via firebase cloud functions. deliver automated phone service with the help of the dialogflow phone gateway, within a minute we can easily add the dedicated phone number into our dialogflow agent and the users who call the agent with the new phone number will contact your dialogflow agent directly. the phone gateway is based on the cost invested by google in various things such as speech recognition, phone connectivity, speech synthesis, natural language processing, etc. designed for a voice-first world with a single api request, we are able to extend our conversational interface to identify voice communications and produce a voice reply. dialogflow supports synchronous modes and real-time streaming, which are powered by the google cloud text-to-speech and cloud text-to-speech. reply on automatic spelling correction in the chat environments, most of the users interact in a hurry, and sometime there may be situations where the users do not emphasize on accurate spelling or grammar in their chats. so, in that situation, there is a feature provided by the dialogflow named automatic spelling correction that helps to automatically spell correction mistakes with the help of the technology used by google for search. improve experience with built-in analytics in the dialogflow, the integrated analytics dashboard provides you with a vision for conversational communication. thus, you can customize your bot to better understanding and reply to the user intentions. understand user sentiment for the query of each user, dialogflow performs sentiment analysis, which is powered by the cloud natural language. the score of sentiment analysis is used to distribute the unfulfilled users to the live agents or to gain a well knowledge about which attempts lead to the highest client feeling. deploy across platforms and languages it supports more than 20 languages with 14 different platforms. bring your enterprise knowledge with the help of the dialogflow knowledge connectors, we can easily augment data in bulk from the enterprise to the agent that contains articles based on knowledge and faqs. to extract the correct answer from the data corpus, the knowledge connectors of the dialogflow use those technologies used by the google assistant and google search. powered by google machine learning the dialogflow tool is powered by google machine learning. in the dialogflow, the understanding of the natural language identify the intent of the users and helps to extract those entities which are prebuilt like a number, date, and time. by offering a small dataset, we can also train the agent to easily recognize the customer entity types. use cases of dialogflow there are various use cases of dialogflow: commerce enterprise productivity iot devices customer service 1. commerce: - the dialogflow is used in business. by using dialogflow, at any time, transactions can be possible with the users on any platform which the user prefers. if you want to purchase goods or schedule deliveries from your users, the dialogflow provides the facility of self-service experience to those users who need rich and personalized replies. 2. enterprise productivity: - we can use dialogflow for enterprise productivity. by using conversational skills inside the workplace apps makes it convenient for workers to access essential information related to the business and increase productivity, for example: offer sales with knowledge associated with the local opportunities. 3. iot devices: - the dialogflow is also used in iot devices. with the help of the conversational interface, we can make our iot devices smarter. the dialogflow adds an intelligent layer to the smart devices and allow devices to understand and respond precisely to the context of a user's interactions. 4. customer service: - with the help of the dialogflow, we can create conversational interfaces that are able to perform different tasks such as scheduling appointments, replies general queries, following up on previous orders, etc. advantages of dialogflow there are various advantages of the dialogflow: sentiment analysis user-friendly incorporates google features swift and more efficient coding can express itself via natural conversation can handle small talks powered by google's machine learning. 1. sentiment analysis: - the dialogflow can perform sentiment analysis for the queries of the user. 2. user-friendly: - the dialogflow is a user-friendly tool, and built with a serverless application structure and an integrated code editor. 3. incorporates google feature: - the dialogflow includes various features of google, such as speech-to-text and machine learning. 4. swift and more efficient coding: - by simplifying the coding process, the dialogflow helps us to save the time of the developers. the developers can efficiently perform all the tasks related to the coding because the system contains a built-in, inline code editor. by using this, their agents can be linked via cloud functions or on-premise to their application. 5. can express itself via natural conversation: - with the help of dialogflow, we can create a chatbot. and the chatbots can make a conversation in a natural manner. it simply means that although the customers speak to an application program or a computer, generally to ask for help or assistance, they will obtain in-context replies. when you communicate in a chatbot, then you will not feel like you are talking with a robotic or mechanical. 6. powered by google's machine learning: - in dialogflow, the machine learning technology is used and it increase the dialogflow's capabilities. why choose dialogflow there are various reasons for choosing dialogflow: multi-channel easy integration price natural language processing 1. multi-channel easy integration: - the dialogflow offers you single-click integrations to various types of the most popular messaging applications such as twitter, skype, kik, viber, facebook messenger, telegram, slack, twilio, and also for several voice assistants such as microsoft cortana, amazon alexa, and google assistant. 2. price: - the free edition of dialogflow is also available if you only learn how to create a chatbot. 3. natural language processing: - the dialogflow uses the concept of nlp (natural language processing), so the dialogflow offers a good user experience. the agents of dialogflow are better at nlp. basics of dialogflow before using dialogflow, there are various things which you should know about the dialogflow. helps users interact with technology the traditional computer system needs predictable and structured input to perform function appropriately, and sometimes it makes the use of interfaces difficult and unnatural. sometimes there may be situation where the end-users cannot grasp this structure input, and, in that situation, the end-users are having a tough time finding out what to do. ideally, the interfaces are able to infer exactly what the end-user wants, based on the natural language end-users use. for example: suppose the request of the user is "how's the weather today"? the other users can also ask: how's the weather right now? how's the temperature in london? what will be the weather on 23 march? as you know, conversational experiences are challenging to implement for these simple questions. the natural language processing and interpreting need a parser of very robust language. dialogflow provides you this type of parser so that you can offer a good quality conversational experience to the end-users. agents the dialogflow agent is defined as a virtual agent whose task is to manage the end -user conversations. an agent is a module that can understand the complexities of the human language. during a conversation, the dialogflow converts the text of end-user or audio into the structured data so that your applications can understand this. the dialogflow agent is designed to manage the kinds of conversation your system needs. the dialogflow agent is the same as an agent in a human call center. both are trained to handle the conversation scenario and don't need to be over explicit in their training, intents an intent classifies the intention of an end-user for one conversation turn. for every agent, we have to define various users, and our combined agent is capable of handling an entire conversation. at the time, when the end-user says or writes something which is denoted as end-user expression, then the dialogflow check and matches the end-user expression to your agent's best intent. intent matching is also called intent classification. for example: if you need to make an agent for the weather, which has the capability to identify and respond to the queries of the end-users related to the weather. then you have to define an intent for the weather forecasting questions. when an end-user asks, "what is the forecast?" then the dialogflow check and match the end-user expression to the intent of the forecast. if we want to obtain the essential information from the end-user expression such as location, time for the weather forecast according to our desire, then we have to define our intent. the obtained information is essential to the system for performing the queries related to the system. the following things are comprised in the basic intent: training phrases action parameters responses 1. training phrases: - training phrases means an example phrases for what the end-users can say. if one of these phrases resembles an end-user expression, then the dialogflow matches the intent. there is no need to define each possible example as the built-in machine learning of dialogflow expands with other related phrases on your list. 2. action: - for the agent, we can define an action. at the time, when we match an intent, then the dialogflow gives the actions to the system, and the action can be used to trigger various actions that are already defined in the system. 3. parameters: - at run time, if we want to march an intent then as a parameter the dialogflow gives the value from the expressions of the end-user. every parameter contains a type known as an entity type, and the entity type exactly dictates how data is retrieved. the parameters are not like raw input of end-user. parameter means structured data, which is used to perform logic or produce responses. 4. responses: - we can define speech, visual, or text replies to return to the end-user. these are able to give the answer to the end-user and also ask for more information to the end-user and can also terminate the conversation. the below figure shows the basic flow for intent matching and responding to the end-user. entities there is a type of every intent parameter, which is known as an entity type. the task performed by the end-user is to explain how data can be extracted from the end-user expression. the dialogflow offers you a various system entity which are predefined, which is able to match various types of common data. for example, there are various types of system entities for matching email addresses, colors, time, date, etc. for matching custom data, we can also make our custom entities. for example: we can define a fruit entity that matches the kinds of the fruits which are available to buy with the agent of a grocery store. dialogflow console dialogflow console is defined as a web user interface which is provided by the dialogflow. the dialogflow console is used to build, test, and create agents. the dialogflow console and google cloud platform console are different from each other. the main task of the dialogflow is to control the dialogflow agents, and the main task of the google cloud platform console (gcp) is to handle the settings of the google cloud platform (gcp) dialogflow such as billing and some other resources of the google cloud platform (gcp). with the help of dialogflow console, we can also create an agent. context the context of dialogflow is the same as a natural language context. when a person tells you, "they are blue," you have to grasp the context to know which they are referring to. in the same way, for dialogflow, in order to handle an end-user expression, the dialogflow context must be provided to match an intent appropriately. to handle the flow of the conversation, contexts are used. by setting input and output contexts, that are recognized by the string names, we can configure the contexts for the intents. if the intent is matched, then for that intent, any configured output context will be active. when the contexts are in the active state then the dialogflow try to match intent configured to the input contexts which is corresponding to the contexts which are presently active. the below figure shows an example which uses context for the banking agent: end-user asks their checking account details. then the dialogflow try to match the expression of this end-user to the intent of there is a checking output context for this intent, which makes that reference active. the agent asks the end-user regarding which kind of information they want, related to their checking account. then the end-user provides replies by "my balance." this end-user expression matches with the intent of checking balance. there is a checking input context for this intent that should be active so that this intent can be matched. in a similar manner, there is another intent named savingsbalance that matches a similar expression of the end-user if the savings context is active. if the required database is queried by our system, then with the help of checking account balance, the agent will reply. follow-up intents the follow-up intents can be used to create contexts automatically for the pairs of intents. a follow-up intent means a child of the intent of its associated parent. when the follow-up intent is created, then automatically an output context will be added to the parent intent, and in the follow-up intent, the input context having a similar name will be added. a follow-up intent is matched only in one situation, and the situation is, if the parent intent is in the turn of previous conversational. multiple levels nested follow-up intents can also be created in the dialogflow. in the dialogflow, there are various types of predefined follow-up intents for the replies of the common end-user such as cancel, yes, no, etc. to manage the responses of the customer, we can also create our own follow-up intent. user interactions with integrations there are various types of conversation platforms on which the dialogflow can integrate, such as facebook, slack, google assistant, etc. to create an agent for any platforms, you can use one of the options from the various integrations' options. in the dialogflow, there is a facility of handling direct end-user interactions so that your more focus is to create an agent. user interactions with the api if any of the integration options you are not using, then you have to write a code that can interact with the end-user directly. for each conversational turn, you have to interact with the api of dialogflow directly so that you can send the expression of end-user and obtain intent matches. the below figure shows how the processing flows when interacting with the api. the end-user is speaking or types the phrases. in the detect intent request message, your service sends the end-user expression to the dialogflow. then, the dialogflow sends your service a message of intent to detect an answer. the information include in the message are related to the parameter, action, the responses and the matched intent declared for the intent. your service performs those actions which are needed, such as external api calls or database queries. your service sends the replies to the end-user. the end-user can hear or see the replies. fulfillment for integrations by default, the agent will react with a static response to a matched intent. you can get a more dynamic response with the help of fulfillment, if you use one of the integration options. for an intent when the fulfillment is enabled, then the dialogflow answer to the intent by calling that service, which you define. for example: if the end-user wishes to schedule a shopping on monday, then your service will search your database and provide the response to the end-user with details on the availability for monday. to enable fulfillment, every intent contains a setting option. when intent need a dynamic response or an action by your system, then for the intent, you have to enable the fulfillment. if without enabling the fulfillment, an intent is matched, it means the dialogflow uses the static response that you defined for the intent. if, with the fulfillment enabled, an intent is matched, then the request is sent by the dialogflow with the information regarding the matched intent. your system is able to perform any action which is needed and also provide a response to the dialogflow with information to proceed. the below figure shows the processing flow for fulfillment: an expression is typed or spoken by the end-user. with the intent, the dialogflow matches the expression of the end-user and extracts the parameters. the dialogflow sends a message to your webhook service for a webhook request. the message comprises the several information such as the matched intent, the response defined for the intent, the parameters, and the actions. your service performs various actions, such as external api calls or database queries. a webhook response message is sent by your service to the dialogflow and the message comprises the response which is sent to the end-user. then, the response is sent to the end-user. the end-user can hear and sees the response. components of the dialogflow there are various components of the dialogflow: entity invocation fulfillment request intents response context user says 1. entity: - entity is defined as a knowledge repository that is used by the agent to answer the questions of the user. there are various types of system entities, such as weather, location, date, etc. 2. invocation: - invocation is like saying hello to a friend. 3. fulfillment request: - the dialogflow send a request to retrieve the necessary data, (sent to webhook) the webhook performs the task like determine how to respond and how to send back to the dialogflow. 4. intents: - intents comprises logic and elements to parse the information of the user. it helps to map what the users are saying with the responses. there are various components in the intent, such as events, response, the user says, contexts, and action. 5. response: - the backend system will produce a set of responses, including user calls, webhook, intentions, entities, etc. 6. context: - the context is used to store the values of the parameter for several kinds of intent. with the help of the context, the broken conversation can also be repaired. 7. user says: - user says means there are various forms of the same question that can be asked by the user. we can add more variations so that the agent can understand in a better way. how to create your first dialogflow agent there are various steps to create your first dialogflow agent: 1. first, we have to log in to the dialogflow. we can log in to the dialogflow by using the link https://dialogflow.com/. after login successfully, we have to click on the sign up for free. then we have to connect with the google account. if you want to use a dialogflow, then it is must that you have a google account. 2. next, we have to click on the create agent to create a new agent. for this, first select the three things: language, the default time zone, and the name for your new bot. 3. then, create the bot say hello. the bot currently doesn't know how to respond to the user input. the journey to teaching it how to behave is just beginning. first, you have to model the personality of the bot a bit and answer hello to him/her and then present yourself. 4. click on the option named default welcome intent. 5. next, we have to add 'hello' and 'hi' to training phases, and these will be in the text form and then click on the enter button. 6. next, we have to go down on the option named responses and remove or delete the existing ones. 7. then, click on the add responses, and then we have to click on the text response then type the response which you want. 8. when you text the response appropriately, then you have to save the response by clicking on the save button. how to import the example file to your agent there are various steps to import the example file to your agent: 1. first, you have to download the new-agent.zip file. 2. then go to the dialogflow console. 3. then, choose an agent. 4. next, click on the setting icon, which is present next to the agent name. 5. then, choose the export and import 6. last, select the option named restore from zip and then to restore the file which you downloaded, you have to follow some instructions on each step. how to create a new intent in this section, we create an agent which is capable of answering the question such as "what is your name". for every intent we have to define various training phrases. a training phrases is also known as end-user expression. it is an example of what the possible questions the end-user can say or type to the agent. we can define any number of training phrases which offer dialogflow, a different type of expressions which must match the intent. there are following steps to create a new intent: 1. first, we have to click on the add intent + button on the left sidebar menu next to the intents. 2. next, click on the get-agent-name, which is present in the intent name 3. then, click on the option named add training phrases, which is present in the training phrases 4. next, we enter the training phrases according to the requirement of the intent. then we have to click enter after every entry. what is your name? tell me your name? do you have a name? note: in most of the cases, it is must that we have to enter at least 10-20 training phrases so that the intent matching is reliable. 5. then, in the response section, we have to enter the response, such as "my name is abc" in the text response section. 6. click on the save button. 7. then, we have to wait till the dialog of the agent training indicates that training is complete. type what is your name into the simulator? click enter. your agent gives correct responses to the expression, no matter if the expression may be a little bit dissimilar from the training phrases that you supplied. for a machine learning model, the dialogflow uses training phrases like an example, to match the expression of the end-user to the intents. against each intent, in the agent, the model tests the expressions and then provides a score to each intent, and then the intent which contains the highest score is matched. when the intent having the highest-scoring has a very less score, then the fallback intent is matched. how to create parameters in dialogflow whenever at runtime, the intent is matched, then as a parameter, the dialogflow gives the values extracted from the end-user expression. and every parameter has a type which is known as an entity type. type of entity dictates exactly how data is extracted. there are following steps to create a parameter: (create a new intent with parameters) 1. first, we have to click on the add intent + button on the left sidebar menu next to the intents. 2. then, we have to give the name to the intent, and the name is as set-language, which appears at the top side of the intent form. 3. now, we have to add the following training phrases: i speak english i know how to write in spanish i know french 4. now, we click on the save button, and then we have to wait for the agent training dialog indicating that agent training completed. automatically, in the training phrases, the dialogflow recognizes parameters which are known as system entities. these are the entities which the dialogflow gives for various common data types like date, color, and location. note: we can annotate our training phrases manually if our training phrases are not annotated automatically. in the action and parameters table, the dialogflow creates a row, which is present below the training phrases. required: - the required parameter is optional because the checkbox is not checked. parameter name: - the parameter name is language because it recognizes the parameter as a language. entity: - entity is a type of entity. the entity is recognized like @language system entity. value: - value is the identifier that you use whenever referring this parameter to its value. is list: - the checkbox of is list is not checked. thus, the parameter is not a list. note: we can also manually annotate the entity in the training phrases if it is not detected automatically. test your parameter if you want to test your parameter then first you have to type 'i know french' and then press enter. we can easily find that the dialog extracts the language parameter appropriately with the value spanish and spanish is appropriately inserted where the reference of the parameter was used in the response. how to create your own entities dialogflow provides you the facility to create your entities because there may be situations when you want to gather specific data from the users, which is not given by the system entities. so, to handle this, you can create a custom entity. there are various steps to create your own entity: 1. first, you have to click on the button add entity +, on the left sidebar menu to the entities 2. then for the entity name, you have to enter language-programming. 3. now, add the below entity entries: 4. then, click on the save button, and then wait till the agent training dialog indicates that agent training completed. the dialogflow can easily handle a few things such as capitalization and plurality, but for the entries, you have to add all the possible synonyms. if you add more synonyms, then the agent can quickly determine the entities. how to use your new entity if you want to make the use of the new entity, then you have to add the training phrases to the set-language. there are various steps to use your new entity: 1. irst, click on the option named 'intents', which is present on the left sidebar menu. 2. then, click on the intent set-language. 3. next, you have to add the various training phrases: i know javascript. i know how to code in java. 4. note that the programming language in these training phrases are annotated automatically and added to the section of action and parameters. 5. next, you have to add another test response, which is $language-programming is a better programming language. 6. then, click on the save button, and then you have to wait till the agent training dialog indicates that agent training completed. test your new entity if you want to test your new entity, then type i know how to code in py and press enter. we can easily see that the dialogflow extracted the py from the parameter language-programming and recognized py as python entity, and then in the response, value is inserted. contexts we can use contexts to manage the flow of conversations. how to add a follow-up intent the follow-up intent is used to handle the conversation. in this to handle a conversation, there is no need for manual creation of the contexts. when the follow-up intent is created, automatically, an output context will be added to the parent intent. in the follow-up intent, the input context having a similar name will be added. only in one situation, a follow-up intent will be matched, and the situation is if the parent intent in the previous conversational turn is matched. there are various steps to add a follow-up intent to the set-language intent: 1. first, choose the intent set-language that is created previously. 2. then, we have to update the test response in the response wow! just wow! i did not know that you knew the $language. 3. then, click on the save button, and then wait till the agent training dialog indicates that agent training completed. 4. now, click on the intents option, which is on the left side of the sidebar menu. 5. hover the mouse over the intent named set-language and then click on the add follow-up intent. 6. then, in the revealed list, click on the custom 7. last, click on the save button, and then wait till the agent training dialog indicates that agent training completed. automatically the dialogflow gives the name to the follow-up intent, and the named is set-language-custom. how to customize the default welcome intent if you want to customize the default welcome intent, there are few things which you have to keep in mind regarding your greeting, and the things are set expectations, let the user take control, and welcome the user. there are various steps to customize the default welcome intent: 1. first, click on the default welcome intent. 2. next, navigate to the responses section. 3. now, remove all the default responses in the text response. 4. then, in the test response, type the response such as "welcome. i can tell you the hours of the shop, or i can arrange an appointment. what one you want?". click on the save button. 5. now, test the customize default welcome intent with the help of the simulator. how to create response variants after creating a phrase of a new greeting, next step is to create some other variations. there are various variations responses which we include in the default welcome intent: hi there. i can help you to tell you the hours of the shop, and i can arrange an appointment. how can i help you today? i will tell you the hours of the store, or i can help you to schedule an appointment. how can i help you? if you add many responses for the intent, then the dialogflow chooses one of the responses from the list in a random way. how to create a custom intent here let's take an agent of the car shop, and we want to perform two tasks from the car shop agent: we want to schedule appointments for the customers. we want to inform the customers regarding the operation hours. now first, we build an intent for the customers, which helps the users to notify regarding the operation hour's for the car shop. we can do this by writing a very dialogflow sample as described below: user: on what time you will be open. agent: we are available daily from 10 am to 8 pm. is there anything else that i should do for you? we have to perform the following steps to make the intent which is able to handle this dialogflow: 1. first, we have to create a new intent and give a name to the new intent as hours. 2. now, we enter the various training phrases in the hours intent training phrases section. on what time you will be open. 3. next, in the response section, we have to type the response in the table of the text response: we are available daily from 10 am to 8 pm. is there anything else that i should do for you? 4. then, we have to click on the save button. add more training phrases previously, we added only one training phrase to the hour's intent. that is "on what time you will be open,". this intent contains no sufficient or enough knowledge that can be helpful to recognize the other same words which have a similar meaning. so, we have to give more training phrases to the intent so that the agent can match different types of user words that can express a similar intention. there are so many ways of forming the phrase in natural language having same meaning. we suggest that each intent starts with at least 10-20 training phrases, depending on the intent complexity. when we begin testing an agent, then using the training tool of dialogflow, add more training phrases. with the training phrase "on what time you will be open?", we can add various variations that user can say instead: business hours on what time you will close are you open now? are you open tomorrow? when do you close? what time do you open tomorrow? how late can i come in? are you open today? please tell me about opening hours? the following steps are performed to add these above variations: 1. first, click on the intent, which we have created already as hours. 2. then enter the above mention phrases in the training phrases 3. now, click on the save 4. then, we test the intent with the help of the simulator in the dialogflow console. how to customize the fallback intent in the dialogflow, there is a fallback intent, which is matched when the utterance of the user did not matched with another intent. as the default welcome intent, the name of the fallback intent name is default fallback intent. a fallback intent is the one that prompts the users whose utterances are formed in such a way that the agent can understand it easily. there are various steps to customize the fallback intent: 1. first, we have to click on the default fallback intent. 2. then, go to the responses 3. now, delete all the default responses which are present in the test response section. 4. next, we have to add the following training phrase in the text response section: sorry, would you like to hear about hours, or you want to set up an appointment? 5. click on the save button. create an intent with parameters now we will build an intent which is able to schedule an appointment for the shop of the car. it is not like that intent, which we created previously. this intent can help to perform more complex tasks. let's discuss the user-agent interaction that follows: user: hi. agent: welcome. i would tell you the hours of the shop, or i can make an appointment. what one you like? user: i want to schedule an appointment at 5 pm today. agent: ok, i schedule your appointment on monday, july 1, at 5 pm. good-bye. the user utterance in the dialogflow that is "i want to schedule an appointment at 5 pm today" comprises of some essential information, which is '5 pm' and 'today'. it helps to identify at which day and time the user needs to visit the shop of the bike. the response of the agent comprises of the information regarding the date and time mentioned in the utterance of the user, which is "ok, i schedule your appointment on monday, july 1 at 5 pm. good-bye." to identify the essential information is very easy for the human, but for the machine, it's not an easy task. so, we have to provide the capability to the intent to extract the essential information, parameters from the utterance of the user. extract information using entities and parameters in a dialogflow, there is a concept of entities and parameters. entities and parameters are used for information extraction from the utterances of the user and then transform the extracted information into a set of parameters, and then it can be processed by systems or functions to perform several tasks. there are various steps to create a new intent with the parameters: 1. first, we create a new intent, and to create a new intent, click on the create intent option and provide a name to the intent as make appointment. 2. then, add the following training phrases in the training phrases section: "i want to schedule an appointment at 5 pm today". 3. next, we verify that the entities of the system, which are @sys.time and @sys.date, have appeared in the action and parameters 4. then, we add the following response phrase in the test response section: "ok, i schedule your appointment on monday, july 1, at 5 pm. good-bye." 5. then, click on the save by using this setup, the make appointment intent verifies the user statements, captures words that are mapped to the built-in system entities of the dialogflow, which are @sys.time and @sys.date. then, places all the captured values in the $date and $time parameters. thus, we use $time and $date system entities in the response to the values of time and date obtained from the user statement or utterances. "ok, i schedule your appointment on monday, july 1, at 5 pm. good-bye." in the dialogflow, we can also create custom entities to extract uncategorized or uncommon parameters. in our case, however, the system entities are enough to capture the usual parameters like date and time. obtain required parameters using slot-filling in addition to the current training phrases, now we are require to include some more training phrases, following the best practices from the previous section, which is "i want to schedule an appointment at 5 pm today". now we add the various training phrases: can i schedule an appointment tomorrow at 6 pm? may i arrange a noon appointment on monday? till now, every training phrase includes information such as date and time, which are 6 pm tomorrow, 5 pm today, noon on monday. but in the real world, it is not must that the user utterances always contain all the needed parameters. now add the below training phrases: i want to fix my car on this monday. my car is cracked. i would like to make an appointment on this monday. can you fix my car? the phrases which we used above indicate that the user needs to make an appointment or schedule an appointment. so, the new intent is able to match with such phrases to manage the job of appointment scheduling. however, the information regarding time and date are not included in the phrases. these types of phrases create problems because, without the information of time and date the intent cannot make an appointment. so, to solve this problem, the dialogflow offers a feature of slot-filling, which ensures that the user gets all the required information from the user. if we want to enable the feature of slot-filling, then we have to mark the required parameters. suppose an intent contains necessary parameters, but it coincides with the utterance of the user, which lacks any needed parameters. in that case, the intent immediately queries the user to get all the parameters which are needed. let's have a look at the following: user: hi. agent: welcome. i can tell you the hours of the shop, or i can make an appointment. what one you like? user: i want to fix my car. agent: alright, i will help you with this. what day would you like to come? user: monday agent: and what time does it work for you? user: 5 pm agent: ok, i got it. i've scheduled your appointment for monday, july 14, at 5 pm. see you early. bye-bye. we have to follow the following steps to make the $time and $date parameters available and include prompt questions about the parameters: 1. first, we have to click on the intent named make appointment. 2. then we check the required boxes for the parameters, which are $time and $date in the actions and parameters then, a column is created named prompts. 3. next, we check that if the parameter $date is located in the table below the parameter $time, then we drag the $date parameter row which is above the parameter $time. (the order in which the prompt questions are asked is decided by the placement in the table.) 5. for parameter $date, we have to click on the link named define prompts that is present in the prompts column, and then we add the prompts which are mentioned below: okay, on which day will you come in? sure, i will help you with this. what day would you like to come? ok, what day would be the best suit for you. 5. then, for parameter $time, we have to click on the link named define prompt present in the prompts column, and then we add the prompt which is mentioned below: ok, what day would be best suit for you? what time? now, what time would you like to schedule your appointment. 6. click on the save button. 7. now, with the help of the simulator, we test the setup of the slot-filling in the dialogflow console. now we have an intent to ensure that the date and time information is retrieved until a user states that they need to make an appointment. however, currently, the intent can only respond to the mock-up response; the actual appointment cannot be scheduled. now there is a need to make a backend process fulfillment, which is able to perform the job of appointment scheduling on google calendar. knowledgebase in dialogflow in the dialogflow, there is a concept of the knowledgebase. we can define a knowledgebase as a set of knowledge document that we offer to the dialogflow. the knowledge document comprises the information, which can be useful in the end-user's conversations. few of the features of dialogflow use the concept of knowledge bases when searching for the end-user expression response. how to create a knowledge base there are various steps to create a knowledge base: 1. first, go to the dialog console. 2. then choose the agent. 3. now, click on the option named knowledge, which is present on the left side of the menu bar. 4. next, click on the create knowledge base 5. then enter the name of the knowledge base and then click on the save button. how to add the document to the knowledge base currently, there is no document contained in the new knowledge base. so, we have to add the document in the knowledge base as per our need. there are various steps to add the document to the knowledge base: first, go to the dialogflow console. then, choose the agent. next, click on the option named knowledge which is present on the left side of the menu bar. then, click on the knowledge base name in which we want to add the document. click on the option named create the first one or new document. then, enter the name of the document. now, select the mime type, which is text/html. next, for the knowledge type, we have to select the option faq. then, for the data source, choose the now, in the url field we have to enter the url that is https://cloud.google.com/storage/docs/faq. then click on the create button. manage knowledge document manage knowledge document contains two essential points. update knowledge document content delete knowledge documents list knowledge documents 1. update knowledge document content: - if you want to update the content of the knowledge document, then you cannot automatically refresh your knowledge document. you have to call the method named reload on the document type to refresh the content of the public uri document or cloud storage. if you want to refresh upload raw content, rebuild your document using the methods delete and create on the document type. 2. delete knowledge documents: - if you want to delete the knowledge document, then you have to call the method named delete on the document 3. list knowledge documents: - if you want to create a list of all your knowledge document, then on the document type, use the api and call the method list. supported content there are various knowledge document types that are supported: faq: - the faq documents are the type of those documents in which the question and answer sets include like csv or html. extract qa: - extract qa are the documents that extract unstructured test and use it for answering questions. the below table shows the supported mime types by source and knowledge type: knowledge type\source uploaded file (document.raw_content) (recommended) uploaded file (document.raw_content) ( not recommended) file from public url (document.contenturi) file from cloud storage (document.contenturi) faq text/csv test/csv text/html text/csv extract qa text/plain, text/html, application/pdf test/plain, test/html n/a text/plain, text/html. application/pdf. training in dialogflow after training the agent to develop a machine learning model mainly for the agent, the dialogflow uses the training data. if we want to provide the training data directly, then the dialogflow offers you the feature of the training phrases by which we can directly enter the training data to the intents. in the dialogflow, there is a training tool that we can also use to improve, export, and import actual conversation data and to analyze our training data. how to execute training in the dialogflow, whenever we save the agent, then automatically, the training is executed. the dialogflow provides the training status whenever you save your agent, and the status is in the form of a pop-up notification. before testing the agent, we have to wait until the training completes. when our agent contains more than 780 intents, or the automatic training status setting is disabled, then we can execute training manually. there are various steps to execute training: 1. first, go to the dialogflow console. 2. then, select the agent. 3. now, click on the setting button, which is next to the name of the agent. 4. then, click on the ml settings tab. 5. click on the train button which is present on the bottom of the page. if we want to execute the training by using api, then we have to call the method named train on the agent type. training tool with the help of the training tool, we can improve the training data. it is used to review conversations with the end-users that your agent had. with the help of the training tool, we can do the following things: we can import the conversation data from the real conversations that you planned or recorded. with the help of the training tool, we can analyze the real conversations and the intents that were matched for every conversation turn. we can attach the expressions of the end-user from the conversations to the training phrases of the formerly matched intents, fallback intents, or the different intents. if you want to use the training tool, then it is must that the logging is enabled because the training tool uses the history of the agent data to load the conversations. the training tool only displays the expressions of the end-user. with the help of the more complete agent history, we can view the conversation data of both agents as well as the end-user. there are various steps to open the training tool. first, go to the dialogflow console. now, select the agent. then, click on the training option, which is present on the left side of the menu bar. conversation list when we open the training tool, then it will show you the list of conversations. this list contains all the recent conversations but in the reverse chronological order. in the list, each row gives you a summary of the conversations. the below table describes each element of the ui. ui element description conversation it is the first expression of the end-user in the conversation. requests it is the number of conversations that turned in the conversation. no match it is the number of conversations turn for which no intent was matched. date the date when the conversation was imported or occurred when we used the conversation to update the training data, then for the row, the status indicator shows a green checkmark. intent matching with follow-up intents the follow-up intent is matched after the parental intentions are matched. so, the intent language-custom is matched only after the set-language intent is matched. suppose the users just asked the question that how long did you know $language? now we can add the training phrases to the question for possible user answers: there are various steps to intent matching with the follow-up intents: 1. first, click on the intents option, which is present on the left sidebar menu. 2. then, click on the intent named set-language-custom. 3. next, add various training phrases: 5 years about 6 days for 7 years 4. last, click on the save button, and wait till the agent training dialog indicates that the agent training completed. test your follow-up intent if you want to test your follow-up intent, then, in the simulator, enter, i know spanish, and then respond to the question how long did you know spanish with about 4 weeks. as we know for the expression about 4 weeks, there is no response, and we can easily see that the expression is matched appropriately to the accurate intent set-language-custom. the parameter for the duration is accurately parsed (4 weeks). contexts and parameters in the context, the values of the parameter are stored. we can access the parameter values, which are defined in the intent set-language when the output context of the set language intent is active. in the set-language-custom, we can only ask one thing, which is the duration of the language that the user knows. we have to perform the following steps to reference the language in the response: 1. first, update the intent set-language-custom to text the response, and the response is i cannot believe you know #set-language-followup.language for $duration! 2. then click on the save button, and then wait till the agent training dialog indicates that the agent training completed. the #set-language-followup.language reference is called a parameter reference for an active context. test the context parameter if you want to test the context parameter, then type i know french in the simulator. then answer the question as 'one week'. note that the value of the parameter is received from the context. interaction with an integration there are various types of conversation platforms on which the dialogflow can integrate, such as facebook, slack, google assistant, etc. to create an agent for any platforms, you can use one of the options from the various integration options. in the dialogflow, there is a facility of handling direct end-user interactions so that your more focus is to create an agent. how to enable the integration there are various steps to enable integration: 1. first, go to the dialogflow console. 2. then, select an agent. 3. next, click on the option named integration present on the left sidebar menu. 4. then, enable web demo integration. when the web demo enables the dialog, the window offers you the following: it provides you the url to a web page that hosts the integration. it provides html code so that the agent in your website can be embedded. it also provides a link for the agent setting, which is used to customize the webpage aspects. how to interact with your agent if you want to interact with your agent, use the above provided link, open the webpage of the agent. this webpage gives you a text chat interface. you have to type what's your name and then click enter. then the agent provides the response with the response which you set up in the previous quickstart. how to build resume chatbot for google assistant there are various steps to build resume chatbot for google assistant: 1. google signup first, log in to the dialogflow. we can log in to the dialogflow by using the link https://dialogflow.com/. after login successfully, we have to click on the sign up for free. then we have to connect with the google account. if we want to use a dialogflow, then it is must that to have a google account. 2. agent creation if we want to develop a new chatbot in the dialogflow, then we have to create an agent. to create an agent, first click on the option name 'create agent' then, give a name to our agent, and then we have to select various things such as default time zone and default language as per our need. 3. create new intent next, we have to create a new intent. we can create a new intent by clicking on the symbol +, which is next to the intents option or by clicking on the button create intent, which is present on the top of the dialogflow window. type intent name (introduction) and click on the save button. then, in the training phrases section, there is a textbox. so, add the user expression in the textbox, and after enter, click on the save button. as per the intent, we need to enter the training phrases. we have to decide which type of user input is going to invoke this intent. such as for the introduction intent, we added "introduce yourself" and "tell me about yourself'. then we go to the responses section. at least one response is required for each intent. so, we have to type the response in the text response box and then press enter. after enter, the text responses, click on the save button. multiple responses can also be added in the responses section. intent use responses in a random way from the list in which we have entered the responses. 4. rich responses there are different types of responses available in the dialogflow. we can have each one for different purposes so that our information is shown in a good way. for example: sometimes we may require to display some images, external links, or a list of items. those cases lead to rich responses. according to chat platforms such as google, telegram, slack, facebook messenger, etc., there are various options available for the rich responses, but all the types are not supported on various chat platforms. now we have to click on the symbol +, which is near the default option in the response section, and then from the list choose the google assistant option. then click on the 'add responses' button, and we can see various kinds of responses. 5. suggestion chips in welcome intent suggestion chips are used as a guide for more conversation. suggestion chips help to indicate what to do next, such as introduction, experience, projects, contact. 6. create introduction intent for the introduction intent, we can add various training phrases such as: introduce your self introduction tell me about yourself there are various types of responses that we can use, such as simple response/ basic card/ list/ carousel. but we use simple response for this intent. 7. create experience intent we can add various training phrases for the experience intent such as: tell me about your experience. experience we can use table card and simple response for the response. if we want to represent our data in a data form, then table card is used, it also offers static data. note: if we want to use a table card response, then it require at least one simple response. 8. create projects intent for the project intent, we can use various phrases such as: your academic projects tell me about your projects we can use a simple response or browser carousel card for the response. we can scroll browser carousel card horizontally. we used this card in browser to open selected external links of the website. 9. create career objective intent for the career objective intent, we can use various training phrases like: your career objective your goal we can use suggestion chips/simple response for the response. 10. create an area of interest intent for the area of interest intent, we can add various training phrases such as: what are your interests tell me about your interests we can use suggestion chips or simple response for the response. 11. create educational qualification intent for the educational qualification intent, we can use the various training phrases such as: tell me about your qualifications education educational qualifications for the response, we have various options such as suggestion chips, simple response, and basic card. for display images, text description, title, subtitle we can use basic card response. 12. create strengths and weakness intent for the strengths and weakness intent, we can use various training phrases such as: tell me about your strength and weakness. what are your strengths. we can use list and simple response for the response. with the help of the list response, we can display various items like a list. we can see in the below image that in the response we have added the needed values. this mean that if the user clicks on the specific item, the next user input will be the key of that item. 13. create contact intent for the contact intent, we can use the various training phrases such as: how can i contact you? your contact details for the responses, we have different kinds of options such as text response/ simple response/ browse carousel card. 14. create references intent for the reference intent, we can use training phrases such as: what are your references for the response, we can use basic card, simple response, link out suggestion, and suggestion chips. we have used link out suggestion we want to link the external website url. anchor text will be the title of the link. 15. create exit intent for the exit intent, we can use various training phrases such as: farewell bye bye get lost good bye bye we can use text response/ simple response for the response. we can see in the below figure that for end, the conversation of this intent, we select/ turn on "set this intent as end of conversation: switch/button/option. if the user enters or type good bye, bye bye or bye then the simple response will be appear. when we make the intent as "end of conversation" then our conversation will end and user exit from the app. now our resume chatbot has been created. how to build an appointment scheduler with dialogflow there are various steps to build an appointment scheduler with dialogflow: create a dialogflow agent create intent test the chatbot enable web integration 1. create a dialogflow agent if we want to build an appointment scheduler with dialogflow then first we have to create a dialogflow agent: there are various steps to create a dialogflow agent: first, go to the dialogflow console. next, as using the dialogflow first time, sign in with the email; otherwise, it is not required. then accept the terms and condition, and after accepting terms and conditions, we can use the dialogflow console. now, we can create the agent by clicking on the create new agent option, which on the left sidebar menu. then, give the name to the agent as "appointment scheduler" and click on the 'create' button. in the dialogflow, as a part of the agent, there are two types of default intents: 1. default fallback intent: - it helps to capture those questions which the bot doesn't understand. 2. default welcome intent: - the default welcome intent is matched whenever the end-user starts a conversation with your agent. test the agent there is a testing panel in the dialogflow console that is used to test the agent. the testing panel appears on the right side of the dialogflow console window. type "hi" to test the agent. then the agent will respond with the default greeting, which is defined in the default welcome intent. it will say, "greetings! "hello! how can i help you?" we can update the response. if we type "set an appointment," then the agent will not be able to give the response to this because the agent does not know what to do and so it provides the response, which is defined in the default fallback intent. because we have not created any intent that catch this specific question. 2. create intent after creating the agent, we have to create the intent. there are various steps to create the intent: (a) first, click on the intent option which is present on the left side of the dialogflow window then click on the create intent (b) then, click on the training phrases and enter the various phrases: i need an appointment on saturday at 4 pm. schedule an appointment on monday at 5 pm. i'd like to arrange an appointment on wednesday for 2 pm. when we enter the above phrases, we will see that the date and time are automatically recognized as system entities, which are @sys.date and @sys.time. (c) next, go to the responses, and in the text response section, enter "you are all set, see you then! we can also write this in another way, like "you are all set for $date at $time." if we add a dollar($) sign, the system can easily access the entity values and click on the add responses. (e) then, click on the save button. then, we will test the agent. slot filling now, "set an appointment" will be tested. this is not really clear and you didn't need to deal with the situation. thus, the default fallback intent handles this, and we can use slot filling for this purpose. slot filling enables you to build a parameter-value-collection conversation flow in a single intent. slot filling is helpful in the situation where without a set of parameter values we cannot complete an action. there are various steps to setup slot filling: 1. first, click on the 'action and parameter' option. make the needed entities, and ask for the date and time in dialogflow before answering. 2. for date, we enter or type "what date?" 3. for time, we enter or type "what time would you like to come in?" 4. then, we click on the 'save' button. 4. test your chatbot now our chatbot for appointment scheduler is ready and now we test the chatbot. to test the chatbot, we have to enter the various conversations in the testing panel of the dialogflow console. user: "hi" chatbot: "greetings! how can i assist? user: "set an appointment" chatbot: "what date?" user: "25 july" chatbot: "what time would you like to come in?" user: "9am" chatbot: "you are all set for 2020-07-25 at 09:00:00. see you then!" now we can see in the above screenshot that the chatbot we developed is working correctly. 5. enable one-click web integration if we want to share the schedule with others, use the option named one-click we integration. in dialogflow, there are various types of integration available for the chatbot. look at a sample chatbot web user interface. there are various steps to use one-click web integration: 1. in the dialogflow, click on the 2. then enable the web demo. 3. next to launch the web demo, click on the url. after performing the above steps, we are able to use the chat interface. we can use the chat interface by typing something where it says 'ask something'. by using the below conversation, we can begin using the chat interface. 1. enter "hi" when you enter "hi" or something then the chatbot will respond you. 2. then, enter "set an appointment for 6 pm tomorrow" and then the chatbot will respond. how to build a chatbot for faq with dialogflow there are various steps to build a chatbot for faq with dialogflow: create an agent enable beta features and apis create a knowledge base handle response test your chatbot create an agent if we want to build a chatbot for faq with dialogflow, create an agent and to create an agent we have to follow the various steps: first, we have to go to the dialogflow console. next, if using dialogflow first time, sign in with your email; otherwise, it is not required. then accept the terms and conditions, and after accepting terms and conditions, we can use the dialogflow console. now, we can create the agent by clicking on the create new agent option, which is on the left sidebar menu. (b) next, give the name to the agent. we are building an agent for the faq. so, we give the related name to this as faq_agent. click on the 'create' button. enable beta features and apis we enable beta features and apis. after enabling the beta features and apis, we are able to create a knowledge connector. create a knowledge base there are various steps to create a knowledge base: (a) first, click on the option named "create knowledge base." (b) then, give the name to the knowledge base, and then save it by clicking on the 'save' button. (c) next, a knowledge document is required, which we will use to auto-generate the chatbot of the faq. we use this faq as a sample. for this purpose, we can also use our document. (d) now, move back further to the dialogflow agent, and then build our first knowledge connector. give the name to the knowledge connector. in this example, we have given the name "faq chatbot." next, choose the knowledge type, which is the faq. then, choose the mimi type, and in this, choose a text/html file as a mimi type. now, add a url to the document https://developers.facebook.com/docs/messenger-platform/faq/. after performing the above steps, click on the create now, the faq chatbot for facebook is created by the knowledge connector, click on the facebook faq. we can see that the questions are parsed into the requests and answers. now, to enable the automated responses, we have to click on the add response and then save. before start testing our agent, firstly enable the chatbot. to enable the chatbot, click the checkbox next to the faq name and press enable. handle responses after creating the knowledge base and adding the faq, our next step is to add some variants under the responses section to check how the chatbot must present the knowledge base's response. the following responses are added in the responses section: i found some information for you: $knowledge.answer[1]. $knowledge.answer [1]. here you go.$knowledge.answer[1]. test your chatbot now, with the help of the simulator, we can test the chatbot. to test the chatbot, type something in the simulator related to the faq. in this example, we created a faq chatbot for facebook. to test the chatbot, we have to type the questions related to the faq facebook chat, such as "can my app use both standard messaging and message tags to send messages." after typing this question, we will get a response from the bot. then, we can also try some more examples like "what happens if my bot messages a person more than once beyond the 24-hour standard messaging window". we will notice that the correct intent is still mapped even if we do not type the particular question from the faq. that's the specialty of the knowledge connector. for videos join our youtube channel: join now feedback send your feedback to [email protected] help others, please share learn latest tutorials splunk spss swagger transact-sql tumblr reactjs regex reinforcement learning r programming rxjs react native python design patterns python pillow python turtle keras preparation aptitude reasoning verbal ability interview questions company questions trending technologies artificial intelligence aws selenium cloud computing hadoop reactjs data science angular 7 blockchain git machine learning devops b.tech / mca dbms data structures daa operating system computer network compiler design computer organization discrete mathematics ethical hacking computer graphics software engineering web technology cyber security automata c programming c++ java .net python programs control system data mining data warehouse javatpoint services javatpoint offers too many high quality services. mail us on [email protected], to get more information about given services. website designing website development java development php development wordpress graphic designing logo digital marketing on page and off page seo ppc content development corporate training classroom and online training data entry training for college campus javatpoint offers college campus training on core java, advance java, .net, android, hadoop, php, web technology and python. please mail your requirement at [email protected] duration: 1 week to 2 week like/subscribe us for latest updates or newsletter learn tutorialslearn javalearn data structureslearn c programminglearn c++ tutoriallearn c# tutoriallearn php tutoriallearn html tutoriallearn javascript tutoriallearn jquery tutoriallearn spring tutorial our websitesjavatpoint.comhindi100.comlyricsia.comquoteperson.comjobandplacement.com our services website development android development website designing digital marketing summer training industrial training college campus training contact address: g-13, 2nd floor, sec-3 noida, up, 201301, india contact no: 0120-4256464, 9990449935contact us subscribe us privacy policysitemap about me Â© copyright 2011-2021 www.javatpoint.com. all rights reserved. developed by javatpoint.
